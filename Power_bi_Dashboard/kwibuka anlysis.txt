# =============================================================================
# KIGALI SMART TRANSPORT INSIGHTS: COMPLETE DATA ANALYTICS PROJECT
# Project: Optimizing Public Transport Operators Through Data Analytics
# Dataset: Rwanda Public Transport Facilities and Operators Dataset
# Author: [ishimwe Egide]
# Date: August 2025
# =============================================================================

# =============================================================================
# STEP 1: INSTALL AND IMPORT REQUIRED LIBRARIES
# =============================================================================

# Install required packages (run these in your Jupyter notebook)
# !pip install pandas numpy matplotlib seaborn plotly folium scikit-learn
# !pip install geopandas contextily

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import folium
from folium import plugins
import warnings
warnings.filterwarnings('ignore')

# Machine Learning libraries
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import silhouette_score

# Set visualization style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("‚úÖ All libraries imported successfully!")
print("üìä Ready to analyze Kigali Transport Data")
# =============================================================================
# STEP 2: LOAD AND EXPLORE THE DATASET
# =============================================================================

# Load the dataset
df = pd.read_csv('merged_transport_data_rwanda_full.csv')

print("üöå KIGALI TRANSPORT DATASET LOADED")
print("=" * 50)
print(f"üìà Dataset Shape: {df.shape}")
print(f"üìä Rows: {df.shape[0]} | Columns: {df.shape[1]}")
print("\nüîç COLUMN INFORMATION:")
print("-" * 30)
for i, col in enumerate(df.columns, 1):
    print(f"{i:2d}. {col}")

print("\nüìã FIRST 3 ROWS PREVIEW:")
print("-" * 40)
print(df.head(3))

print("\nüìä BASIC DATASET INFO:")
print("-" * 25)
print(df.info())
# =============================================================================
# STEP 3: DATA QUALITY ASSESSMENT
# =============================================================================

print("\n" + "=" * 60)
print("üîç DATA QUALITY ASSESSMENT")
print("=" * 60)

# Check for missing values
missing_values = df.isnull().sum()
print("\nüìä MISSING VALUES ANALYSIS:")
print("-" * 35)
if missing_values.sum() == 0:
    print("‚úÖ No missing values found - dataset is clean!")
else:
    print(missing_values[missing_values > 0])

# Check data types
print("\nüìã DATA TYPES:")
print("-" * 20)
print(df.dtypes)

# Check for duplicates
duplicates = df.duplicated().sum()
print(f"\nüîÑ DUPLICATE RECORDS: {duplicates}")

# Basic statistics for numeric columns
numeric_cols = df.select_dtypes(include=[np.number]).columns
if len(numeric_cols) > 0:
    print("\nüìà NUMERIC COLUMNS STATISTICS:")
    print("-" * 35)
    print(df[numeric_cols].describe())

print("\n‚úÖ DATA QUALITY CHECK COMPLETED!")# =============================================================================
# STEP 4: EXPLORATORY DATA ANALYSIS (EDA)
# =============================================================================

print("\n" + "=" * 60)
print("üìä EXPLORATORY DATA ANALYSIS (EDA)")
print("=" * 60)

# Create figure for multiple subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('üöå Kigali Transport Operators - Key Insights Dashboard', fontsize=16, fontweight='bold')

# 1. Operator Type Distribution
operator_counts = df['OPERATOR_TYPE'].value_counts()
axes[0, 0].pie(operator_counts.values, labels=operator_counts.index, autopct='%1.1f%%', startangle=90)
axes[0, 0].set_title('üöó Distribution of Operator Types')

# 2. Regional Distribution
region_counts = df['REGIONS'].value_counts()
axes[0, 1].bar(region_counts.index, region_counts.values, color='skyblue')
axes[0, 1].set_title('üó∫Ô∏è Operators by Region')
axes[0, 1].set_xlabel('Region')
axes[0, 1].set_ylabel('Number of Operators')
axes[0, 1].tick_params(axis='x', rotation=45)

# 3. Transport Mode Analysis
transport_mode_counts = df['TRANSPORT_MODE'].value_counts()
axes[1, 0].barh(transport_mode_counts.index, transport_mode_counts.values, color='lightgreen')
axes[1, 0].set_title('üöå Transport Modes Distribution')
axes[1, 0].set_xlabel('Number of Operators')

# 4. Peak Time Operations
peak_data = pd.DataFrame({
    'Morning Peak': df['MORNING_PEAK'].value_counts(),
    'Afternoon Peak': df['AFTERNOON_PEAK'].value_counts()
})
peak_data.plot(kind='bar', ax=axes[1, 1], color=['orange', 'red'])
axes[1, 1].set_title('‚è∞ Peak Time Operations')
axes[1, 1].set_xlabel('Operation Status')
axes[1, 1].set_ylabel('Number of Operators')
axes[1, 1].legend()

plt.tight_layout()
plt.show()# =============================================================================
# STEP 5: INTERACTIVE VISUALIZATIONS WITH PLOTLY
# =============================================================================

print("\nüìä CREATING INTERACTIVE VISUALIZATIONS...")

# Interactive map of operators in Kigali
def create_kigali_transport_map():
    """Create an interactive map showing transport operators in Kigali"""
    
    # Filter valid coordinates (assuming Kigali coordinates)
    map_data = df.dropna(subset=['LATITUDE', 'LONGITUDE'])
    
    # Create base map centered on Kigali
    kigali_map = folium.Map(
        location=[-1.9441, 30.0619],  # Kigali coordinates
        zoom_start=12,
        tiles='OpenStreetMap'
    )
    
    # Color mapping for operator types
    colors = {'Taxi': 'red', 'Hire car': 'blue', 'Bus': 'green', 'Motorcycle': 'orange'}
    
    # Add markers for each operator
    for idx, row in map_data.iterrows():
        color = colors.get(row['OPERATOR_TYPE'], 'gray')
        
        folium.CircleMarker(
            location=[row['LATITUDE'], row['LONGITUDE']],
            radius=8,
            popup=f"""
            <b>{row['OPERATOR_NAME']}</b><br>
            Type: {row['OPERATOR_TYPE']}<br>
            Region: {row['REGIONS']}<br>
            Phone: {row['OPERATOR_PHONE']}<br>
            Operating Area: {row['OPERATING_AREA']}
            """,
            color=color,
            fill=True,
            fillColor=color,
            fillOpacity=0.7
        ).add_to(kigali_map)
    
    # Add legend
    legend_html = '''
    <div style="position: fixed; 
                bottom: 50px; left: 50px; width: 150px; height: 120px; 
                background-color: white; border:2px solid grey; z-index:9999; 
                font-size:14px; padding: 10px">
    <p><b>üöå Operator Types</b></p>
    <p><i class="fa fa-circle" style="color:red"></i> Taxi</p>
    <p><i class="fa fa-circle" style="color:blue"></i> Hire Car</p>
    <p><i class="fa fa-circle" style="color:green"></i> Bus</p>
    <p><i class="fa fa-circle" style="color:orange"></i> Motorcycle</p>
    </div>
    '''
    kigali_map.get_root().html.add_child(folium.Element(legend_html))
    
    return kigali_map

# Create and display the map
transport_map = create_kigali_transport_map()
transport_map.save('kigali_transport_operators_map.html')
print("‚úÖ Interactive map saved as 'kigali_transport_operators_map.html'")# =============================================================================
# STEP 6: KEY STATISTICS SUMMARY
# =============================================================================

print("\n" + "=" * 60)
print("üìà KEY STATISTICS SUMMARY")
print("=" * 60)

# Calculate key statistics
total_operators = len(df)
unique_regions = df['REGIONS'].nunique()
unique_operator_types = df['OPERATOR_TYPE'].nunique()
morning_peak_operators = df['MORNING_PEAK'].value_counts().get('Yes', 0)
afternoon_peak_operators = df['AFTERNOON_PEAK'].value_counts().get('Yes', 0)

print(f"üöå Total Transport Operators: {total_operators}")
print(f"üó∫Ô∏è Operating Regions: {unique_regions}")
print(f"üöó Types of Operators: {unique_operator_types}")
print(f"üåÖ Morning Peak Operators: {morning_peak_operators}")
print(f"üåÜ Afternoon Peak Operators: {afternoon_peak_operators}")

print("\nüìä TOP 5 OPERATORS BY TYPE:")
print("-" * 35)
print(df['OPERATOR_TYPE'].value_counts().head())

print("\nüó∫Ô∏è REGIONAL DISTRIBUTION:")
print("-" * 25)
print(df['REGIONS'].value_counts())

print("\nüöå TRANSPORT MODE ANALYSIS:")
print("-" * 30)
print(df['TRANSPORT_MODE'].value_counts())# =============================================================================
# STEP 7: MACHINE LEARNING ANALYSIS
# =============================================================================

print("\n" + "=" * 60)
print("ü§ñ MACHINE LEARNING ANALYSIS")
print("=" * 60)

# Prepare data for machine learning
print("üîÑ Preparing data for machine learning...")

# Create a copy for ML processing
ml_df = df.copy()

# Feature Engineering
# Create binary features for peak operations
ml_df['PEAK_OPERATIONS'] = ((ml_df['MORNING_PEAK'] == 'Yes') | (ml_df['AFTERNOON_PEAK'] == 'Yes')).astype(int)

# Encode categorical variables
label_encoders = {}
categorical_columns = ['REGIONS', 'OPERATING_AREA', 'TRANSPORT_MODE']

for col in categorical_columns:
    if col in ml_df.columns:
        le = LabelEncoder()
        ml_df[f'{col}_ENCODED'] = le.fit_transform(ml_df[col].astype(str))
        label_encoders[col] = le

# Select features for clustering (focusing on location and operation type)
clustering_features = []
if 'LATITUDE' in ml_df.columns and 'LONGITUDE' in ml_df.columns:
    clustering_features.extend(['LATITUDE', 'LONGITUDE'])
if 'REGIONS_ENCODED' in ml_df.columns:
    clustering_features.append('REGIONS_ENCODED')
if 'OPERATING_AREA_ENCODED' in ml_df.columns:
    clustering_features.append('OPERATING_AREA_ENCODED')
if 'PEAK_OPERATIONS' in ml_df.columns:
    clustering_features.append('PEAK_OPERATIONS')

print(f"‚úÖ Selected features for analysis: {clustering_features}")
# =============================================================================
# STEP 8: K-MEANS CLUSTERING ANALYSIS
# =============================================================================

if len(clustering_features) >= 2:
    print("\nüéØ PERFORMING K-MEANS CLUSTERING ANALYSIS")
    print("-" * 45)
    
    # Prepare clustering data
    X_cluster = ml_df[clustering_features].dropna()
    
    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_cluster)
    
    # Find optimal number of clusters using elbow method
    inertias = []
    silhouette_scores = []
    k_range = range(2, 8)
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(X_scaled)
        inertias.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))
    
    # Plot elbow curve
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(k_range, inertias, 'bo-')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Inertia')
    plt.title('üîç Elbow Method for Optimal k')
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.plot(k_range, silhouette_scores, 'ro-')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Silhouette Score')
    plt.title('üìä Silhouette Score Analysis')
    plt.grid(True)
    
    plt.tight_layout()
    plt.show()
    
    # Use optimal k (let's use k=4 for this analysis)
    optimal_k = 4
    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_scaled)
    
    # Add cluster labels to dataframe
    ml_df.loc[X_cluster.index, 'CLUSTER'] = cluster_labels
    
    print(f"‚úÖ K-Means clustering completed with k={optimal_k}")
    print(f"üìä Silhouette Score: {silhouette_score(X_scaled, cluster_labels):.3f}")
    
    # Analyze clusters
    print("\nüéØ CLUSTER ANALYSIS:")
    print("-" * 25)
    cluster_summary = ml_df.groupby('CLUSTER').agg({
        'OPERATOR_NAME': 'count',
        'REGIONS': lambda x: x.mode().iloc[0] if not x.empty else 'Unknown',
        'OPERATOR_TYPE': lambda x: x.mode().iloc[0] if not x.empty else 'Unknown',
        'PEAK_OPERATIONS': 'mean'
    }).round(3)
    
    cluster_summary.columns = ['Operators_Count', 'Dominant_Region', 'Dominant_Type', 'Avg_Peak_Operations']
    print(cluster_summary)
# =============================================================================
# STEP 9: CLASSIFICATION MODEL FOR OPERATOR TYPE PREDICTION
# =============================================================================

print("\nüéØ BUILDING CLASSIFICATION MODEL")
print("-" * 35)

# Prepare features for classification
classification_features = []
if 'REGIONS_ENCODED' in ml_df.columns:
    classification_features.append('REGIONS_ENCODED')
if 'OPERATING_AREA_ENCODED' in ml_df.columns:
    classification_features.append('OPERATING_AREA_ENCODED')
if 'TRANSPORT_MODE_ENCODED' in ml_df.columns:
    classification_features.append('TRANSPORT_MODE_ENCODED')
if 'PEAK_OPERATIONS' in ml_df.columns:
    classification_features.append('PEAK_OPERATIONS')

if len(classification_features) >= 2:
    # Prepare data
    X = ml_df[classification_features].dropna()
    y = ml_df.loc[X.index, 'OPERATOR_TYPE']
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
    
    # Train Random Forest model
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    
    # Make predictions
    y_pred = rf_model.predict(X_test)
    
    # Evaluate model
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"üéØ Model Accuracy: {accuracy:.3f}")
    print("\nüìä CLASSIFICATION REPORT:")
    print("-" * 30)
    print(classification_report(y_test, y_pred))
    
    # Feature importance
    feature_importance = pd.DataFrame({
        'Feature': classification_features,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print("\nüîç FEATURE IMPORTANCE:")
    print("-" * 25)
    print(feature_importance)
    
    # Plot feature importance
    plt.figure(figsize=(10, 6))
    sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')
    plt.title('üîç Feature Importance for Operator Type Prediction')
    plt.xlabel('Importance Score')
    plt.tight_layout()
    plt.show()
# =============================================================================
# STEP 9: CLASSIFICATION MODEL FOR OPERATOR TYPE PREDICTION
# =============================================================================

print("\nüéØ BUILDING CLASSIFICATION MODEL")
print("-" * 35)

# Prepare features for classification
classification_features = []
if 'REGIONS_ENCODED' in ml_df.columns:
    classification_features.append('REGIONS_ENCODED')
if 'OPERATING_AREA_ENCODED' in ml_df.columns:
    classification_features.append('OPERATING_AREA_ENCODED')
if 'TRANSPORT_MODE_ENCODED' in ml_df.columns:
    classification_features.append('TRANSPORT_MODE_ENCODED')
if 'PEAK_OPERATIONS' in ml_df.columns:
    classification_features.append('PEAK_OPERATIONS')

if len(classification_features) >= 2:
    # Prepare data
    X = ml_df[classification_features].dropna()
    y = ml_df.loc[X.index, 'OPERATOR_TYPE']

    # ‚ö†Ô∏è Filter out rare classes with only 1 instance
    value_counts = y.value_counts()
    valid_classes = value_counts[value_counts >= 2].index
    mask = y.isin(valid_classes)

    X = X[mask]
    y = y[mask]

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    # Train Random Forest model
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)

    # Make predictions
    y_pred = rf_model.predict(X_test)

    # Evaluate model
    accuracy = accuracy_score(y_test, y_pred)
    print(f"üéØ Model Accuracy: {accuracy:.3f}")

    print("\nüìä CLASSIFICATION REPORT:")
    print("-" * 30)
    print(classification_report(y_test, y_pred))

    # Feature importance
    feature_importance = pd.DataFrame({
        'Feature': classification_features,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)

    print("\nüîç FEATURE IMPORTANCE:")
    print("-" * 25)
    print(feature_importance)

    # Plot feature importance
    plt.figure(figsize=(10, 6))
    sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')
    plt.title('üîç Feature Importance for Operator Type Prediction')
    plt.xlabel('Importance Score')
    plt.tight_layout()
    plt.show()
else:
    print("‚ö†Ô∏è Not enough features available for classification.")
# =============================================================================
# STEP 10: ADVANCED VISUALIZATIONS AND INSIGHTS
# =============================================================================

print("\nüìä CREATING ADVANCED VISUALIZATIONS...")

# Create comprehensive dashboard
fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('üó∫Ô∏è Regional Distribution', '‚è∞ Peak Operations', 
                    'üöå Transport Modes', 'üìä Operator Performance'),
    specs=[[{"type": "pie"}, {"type": "bar"}],
           [{"type": "bar"}, {"type": "scatter"}]]
)

# Regional pie chart
region_counts = df['REGIONS'].value_counts()
fig.add_trace(go.Pie(labels=region_counts.index, values=region_counts.values, name="Regions"), row=1, col=1)

# Peak operations bar chart
peak_comparison = pd.DataFrame({
    'Morning': df['MORNING_PEAK'].value_counts(),
    'Afternoon': df['AFTERNOON_PEAK'].value_counts()
})
for i, (period, data) in enumerate(peak_comparison.items()):
    fig.add_trace(go.Bar(x=data.index, y=data.values, name=f"{period} Peak", 
                         marker_color=['lightblue', 'darkblue'][i]), row=1, col=2)

# Transport modes
transport_counts = df['TRANSPORT_MODE'].value_counts()
fig.add_trace(go.Bar(x=transport_counts.index, y=transport_counts.values, 
                     name="Transport Modes", marker_color='green'), row=2, col=1)

# Scatter plot (if coordinates available)
if 'LATITUDE' in df.columns and 'LONGITUDE' in df.columns:
    fig.add_trace(go.Scatter(x=df['LONGITUDE'], y=df['LATITUDE'], 
                             mode='markers', name="Operator Locations",
                             marker=dict(size=8, color='red', opacity=0.7)), row=2, col=2)

fig.update_layout(height=800, showlegend=True, 
                  title_text="üöå Kigali Transport Analytics Dashboard")
fig.show()# =============================================================================
# STEP 11: RECOMMENDATIONS AND INSIGHTS
# =============================================================================

print("\n" + "=" * 60)
print("üí° KEY INSIGHTS AND RECOMMENDATIONS")
print("=" * 60)

# Generate insights based on analysis
total_operators = len(df)
dominant_region = df['REGIONS'].mode().iloc[0]
dominant_operator_type = df['OPERATOR_TYPE'].mode().iloc[0]
dominant_transport_mode = df['TRANSPORT_MODE'].mode().iloc[0]

morning_peak_pct = (df['MORNING_PEAK'] == 'Yes').mean() * 100
afternoon_peak_pct = (df['AFTERNOON_PEAK'] == 'Yes').mean() * 100

print("üîç KEY FINDINGS:")
print("-" * 20)
print(f"üìä Total Operators Analyzed: {total_operators}")
print(f"üó∫Ô∏è Dominant Operating Region: {dominant_region}")
print(f"üöó Most Common Operator Type: {dominant_operator_type}")
print(f"üöå Primary Transport Mode: {dominant_transport_mode}")
print(f"üåÖ Morning Peak Coverage: {morning_peak_pct:.1f}%")
print(f"üåÜ Afternoon Peak Coverage: {afternoon_peak_pct:.1f}%")

print("\nüí° STRATEGIC RECOMMENDATIONS:")
print("-" * 35)
print("1. üéØ ROUTE OPTIMIZATION:")
print("   ‚Ä¢ Focus expansion in underserved regions")
print("   ‚Ä¢ Improve coverage in low-density areas")

print("\n2. ‚è∞ PEAK TIME MANAGEMENT:")
print("   ‚Ä¢ Increase fleet during high-demand periods")
print("   ‚Ä¢ Implement dynamic pricing strategies")

print("\n3. üöå SERVICE DIVERSIFICATION:")
print("   ‚Ä¢ Balance operator types across regions")
print("   ‚Ä¢ Promote eco-friendly transport options")

print("\n4. üì± DIGITAL TRANSFORMATION:")
print("   ‚Ä¢ Implement real-time tracking systems")
print("   ‚Ä¢ Develop mobile booking platforms")

print("\n5. üìä DATA-DRIVEN DECISIONS:")
print("   ‚Ä¢ Regular monitoring of operator performance")
print("   ‚Ä¢ Use predictive analytics for demand forecasting")
# =============================================================================
# STEP 12: EXPORT RESULTS FOR POWER BI
# =============================================================================

print("\nüìÅ PREPARING DATA FOR POWER BI ANALYSIS...")

# Create enhanced dataset with ML results
export_df = df.copy()

# Add cluster information if available
if 'CLUSTER' in ml_df.columns:
    export_df = export_df.merge(
        ml_df[['REFERENCE_ID', 'CLUSTER']].dropna(), 
        on='REFERENCE_ID', 
        how='left'
    )

# Add calculated fields for Power BI
export_df['PEAK_OPERATIONS_COUNT'] = (
    (export_df['MORNING_PEAK'] == 'Yes').astype(int) + 
    (export_df['AFTERNOON_PEAK'] == 'Yes').astype(int)
)

export_df['REGION_OPERATOR_COUNT'] = export_df.groupby('REGIONS')['REGIONS'].transform('count')
export_df['TYPE_OPERATOR_COUNT'] = export_df.groupby('OPERATOR_TYPE')['OPERATOR_TYPE'].transform('count')

# Export cleaned dataset
export_df.to_csv('kigali_transport_analysis_results.csv', index=False)
print("‚úÖ Enhanced dataset exported as 'kigali_transport_analysis_results.csv'")

# Create summary statistics for Power BI
summary_stats = pd.DataFrame({
    'Metric': ['Total Operators', 'Unique Regions', 'Operator Types', 
               'Morning Peak Operators', 'Afternoon Peak Operators'],
    'Value': [total_operators, unique_regions, unique_operator_types,
              morning_peak_operators, afternoon_peak_operators]
})
summary_stats.to_csv('kigali_transport_summary_stats.csv', index=False)
print("‚úÖ Summary statistics exported as 'kigali_transport_summary_stats.csv'")

print("\n" + "=" * 60)
print("üéâ KIGALI TRANSPORT ANALYSIS COMPLETED!")
print("=" * 60)
print("‚úÖ All analysis steps completed successfully")
print("üìä Results ready for Power BI dashboard development")
print("üó∫Ô∏è Interactive map generated for geographic insights")
print("ü§ñ Machine learning models trained and evaluated")
print("üí° Strategic recommendations provided")
print("\nüöÄ Next Steps:")
print("1. Import the exported CSV files into Power BI")
print("2. Create interactive dashboards using the analysis results")
print("3. Implement the recommended strategies")
print("4. Set up regular monitoring and updates")